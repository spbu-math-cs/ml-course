# Опишите современную статью или свой проект по машинному обучению

(вдохновлялись [заданием](https://github.com/sim0nsays/dlcourse_ai/blob/master/assignments/paper_post.md) курса Семена Козлова «DL на пальцах»)

Область развивается очень быстро, поэтому постоянно приходится следить или «трогать руками» последние достижения — потренируемся это делать!

Практически все статьи в области Machine Learning бесплатно доступны в интернете, обычно на [arxiv.org](http://arxiv.org).

## Как найти статью, которую стоит прочесть?

Вариантов много!

- Дойти до ссылок на научные статьи из новостей про последние достижения AI, которых [очень](https://neurohive.io/ru/gotovye-prilozhenija/controlflag-instrument-intel-avtomaticheskoj-otladki-koda/) и [очень](https://yandex.ru/blog/company/smotrite-po-russki-yandeks-zapustil-zakadrovyy-perevod-video) [много](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)
- Прочитать в деталях одну из статей, упомянутых в лекциях курса (см. ссылки в слайдах)
- Посмотреть, что является последним достижением (State of the Art или SotA) в какой-то конкретной задаче Хороший ресурс, отслеживающий SotA в большом классе задач - [https://paperswithсode.com](https://paperswithcode.com/). Как пример можно посмотреть на:
  - [Mask attention and transformer](https://paperswithcode.com/paper/masked-attention-mask-transformer-for)
  - [Semantic Segmentation](https://paperswithcode.com/task/semantic-segmentation)
  - [Question Answering](https://paperswithcode.com/task/question-answering)
  - [Distillation framework](https://paperswithcode.com/paper/a-fast-knowledge-distillation-framework-for)
- Поискать статьи по интересующим вас словам через  [http://www.arxiv-sanity.com/](http://www.arxiv-sanity.com/)
- Следить за ссылками в сообществах, связанных с Machine Learning
- Взять одну из статей, которая помогла вам в каком-то из соревнований

Наконец, несколько примеров статей:

- [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) — с чего начался перенос стиля а-ля Prisma
- [Super-convergence](https://arxiv.org/abs/1708.07120) — подход к очень быстрой тренировке сетей
- [SquuezeNet](https://arxiv.org/abs/1602.07360) — пример архитектуры, оптимизированной для мобильных устройств
- [Mask RCNN](https://arxiv.org/abs/1703.06870) — развитие RCNN для задачи Instance Segmentation
- [DenseNet](https://arxiv.org/abs/1608.06993) — развитие базовой архитектуры CNN после ResNet
- [Learning from Simulated and Unsupervised Images through Adversarial Training](https://arxiv.org/abs/1612.07828) — использование GANs для генерации примеров для тренировки
- [OpenAI GPT-3](https://openai.com/blog/gpt-3-apps/) — одна из последних архитектур для обучения языковых моделей
- [Transformer-XL](https://arxiv.org/abs/1901.02860) — развитие архитектуры Transformer
- [TacoTron2](https://arxiv.org/abs/1712.05884) — архитектура для синтеза речи

## Что значит описать?

Напишите пост с кратким описанием задачи, которая решается в статье, ключевой идеи и результата, и выложите его где-нибудь! Допускаются блог посты на любом сайте, посты в чатах telegram, OpenDataScience, видео на youtube итд итп.

Пожелания по посту:

- Описать задачу, решаемую в статье, и главную метрику. Было бы здорово привести примеры сэмплов в датасете, сказать насколько он большой итд
- Описать ключевую идею статьи «на пальцах», в идеале в контексте прошлых подходов или сравнения с неким бейзлайном. Обычно в статьях есть диаграмма, описывающая ключевые моменты, приведите её и объясните что на ней
- Описать результаты. Часто в конце статьи есть таблица сравнения подхода из статьи с другими методами, её тоже стоит привести и объяснить
- Упомяните, что пост написан для https://github.com/spbu-math-cs/ml-course

Вот несколько постов подобного типа в курсах ODS:
- https://habr.com/ru/post/301084/
- https://habr.com/ru/company/ods/blog/352518/
- https://www.alexirpan.com/2017/02/22/wasserstein-gan.html

## Ок, и что потом?
Присылайте ссылки на свои посты на сайт в это домашнее задание.

Лучшие из них мы запостим в соцсетях МКН и конечно устроим соревнование по количеству лайков! :)
